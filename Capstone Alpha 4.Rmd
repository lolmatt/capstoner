---
title: "Capstone"
author: "Matthew Cooke"
date: "July 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("FactoMineR")
#library(FactoMineR)
#install.packages("cba")
#library(cba)
```
#Introduction
We're looking at Mortality data from the US Centre for Disease Control
Lists all deaths recorded in 2015. There are ~2.6 million of them
Retrieved from: https://www.cdc.gov/nchs/data_access/vitalstatsonline.htm#Mortality_Multiple

#Loading the data
This is a fixed width file in DUSMCPUB format, so importing requires a look at the documentation pdf provided at the above link
Columns of form X## are dummy variables, with the exception of X27 which is a list of 20x2 contributing causes of death.
```{r}
mort15 <- read.fwf(file="VS15MORT.DUSMCPUB",
                    widths= c(19,1,40,2,1,1,2,2,1,4,1,2,2,2,2,1,1,1,16,4,1,1,1,1,
                                34,1,1,4,3,1,3,3,2,283,2,1,1,1,1,33,3,1,1),
                    col.names= c("X0","ResidentStatus","X1","Education1989",
                                   "Education2003","EducationFlag","MonthOfDeath",
                                   "X5","Sex","AgeDetail","AgeSubstitution",
                                   "AgeRecode52","AgeRecode27","AgeRecode12",
                                   "AgeRecodeInfant22","PlaceOfDeath","MaritalStatus",
                                   "DayOfWeekofDeath","X15","CurrentDataYear",
                                   "InjuryAtWork","MannerOfDeath","MethodOfDisposition",
                                   "Autopsy","X20","ActivityCode","PlaceOfInjury",
                                   "ICDCode","CauseRecode358","X24","CauseRecode113",
                                   "CauseRecode130","CauseRecode39","X27","Race",
                                   "BridgeRaceFlag","RaceImputationFlag","RaceRecode3",
                                   "RaceRecord5","X32","HispanicOrigin","X33",
                                   "HispanicOriginRecode")
                    )
#mort15<-read.csv("Mortality15.csv")
```
What are the variables?
They include: Age & Cause of Death, with various levels of binning, Sex, Type of Death, Place of Injury and Death, 
Information about education, race, marital status, and so on.

Let's start by getting a look at some of the variables with str and head
```{r}
str(mort15)
head(mort15)
```



#Cleaning
Since this is a very large dataset analysis will take a long time, unless we prepare the data and eliminate any uninteresting or superfluous variables. These can include dummy variables, variables which have 0 variance, entries with missing information, binnings of the same variables and so on. Before we begin it may be prudent to add an id variable so we can keep track of what we've removed so far from the master dataset. (R does this automatically sometimes)
```{r}
mort15[44] <- c(1:2718198) #The starting ID variable
mort15[,c(1,3,8,19,25,30,40,42)] <- NULL # These are the dummy variables 
mort15$CurrentDataYear <- NULL #This is $CurrentDataYear, only included for the benefit of those working with data from multiple years

mort15<- mort15[-which(mort15$AgeSubstitution != "NA"),]
mort15$AgeSubstitution<-NULL #Age substitution indicates records for which age data is unreliable, probably because the people are so old. Since it only includes a handful of records we can delete them all and then purge the column.

length(which(mort15$Education1989 != "NA")) /(length(mort15[,1])) ##Education1989 is an outdated measure of education which is seldom used
hist(mort15$AgeRecode12[which(mort15$Education1989 != "NA")])#It is used overwhelmingly for older persons
which(mort15$Education2003[which(mort15$Education1989 != "NA")] != "NA") ##It is recorded for all and only those records for which there 
##Is no Education2003, at 2.7% of the dataset. We should be able to purge these records and delete the column
mort15 <- mort15[-which(mort15$Education1989 != "NA"),]
mort15$Education1989 <- NULL

mort15$EducationFlag <- NULL #This column marks whether Education1989 was used or not.
mort15[,6:9] <- NULL #These columns are recodes of age into various buckets. These are easy to replace later should we choose to do so.

mort15 <- mort15[-which(mort15$Education == 9),] #9 indicates unknown education. We'll be looking a lot at education later so it's best to prune

#write.csv(mort15, "Mortality15Cleaned.CSV") #Since this takes so long to load we should back up regularly
mort15 <- read.csv("Mortality15Cleaned.CSV")
mort15[,1] <- NULL
```

#Cleaning COD

For this analysis we'll be looking a lot at causes of death. These are recorded in the X27 variable, which is over 200 characters long and has 2*20 entries
for cause of death and contributing causes of death. One group is Entity-Axis records, the other is Row-Axis, a lightly processed EAC which removes errors, contradictions, and sorts alphabetically all contributing causes of death listed on a patient's death certificate. Since this is such a cumbersome part of the dataset we'll load it into its own data frame. Line spacings were taken from the documentation.

```{r}
install.packages("tidyr")
library(tidyr) #We're using the separate function in tidyr
mort15cod <- NULL
mort15cod = separate(data=mort15, col=X27, into=
                   c("neac","eac1","eac2","eac3","eac4","eac5","eac6","eac7","eac8","eac9",
                     "eac10","eac11","eac12","eac13","eac14","eac15","eac16","eac17","eac18","eac19","eac20","blank",
                     "nrac","rac1","rac2","rac3","rac4","rac5","rac6","rac7","rac8","rac9","rac10",
                     "rac11","rac12","rac13","rac14","rac15","rac16","rac17","rac18","rac19","rac20"), 
                 sep=c(3,7*seq(from=1, to=20)+3,146,182,5*seq(from=1, to=20)+182))[,c(42:62,71)]
```

We'll just be using RAC in this case, since 39 dimensions is a lot. We also have the number of conditions listed as nrac. rac1 is equal
to icd10 from the original data frame - the principal cause of death. We also need to keep track of our indicies if we're using a second matrix to handle the data size.

```{r}
mort15cod$nrac <- as.numeric(mort15cod$nrac)

mort15cod[,2:21] <- apply(mort15cod[,2:21],2,trimws) ##We'll also trim the white space while we're at it to normalize

str(mort15cod)
```



In the interests of speeding up the data processing it may be prudent to eliminate some records which list a very large number of conditions. We can check how many people have a number of conditions >X and remove records which correspond to a very small % of the dataset, say <5%.
```{r}

length(which(mort15cod[,9]!=""))/length(mort15cod$nrac)  ## Only 2.2% of records have 8 or more conditions listed.
mort15cod <- mort15cod[-which(mort15cod[,9]!=""),] ##Purge the records
mort15cod[,9:21]<-NULL ##Drop the columns
str(mort15cod)
##We can turn this resulting matrix into a categorical matrix for analysis. 

#mort15cod[,2:8] <- apply(mort15cod[,2:8],2,as.factor) ##Why doesn't Apply work with as.factor?
#mort15cod[,9] <-NULL


mort15cod[,2:8] <- apply(mort15cod[,2:8],2,as.character)
h<- c(unique(unlist(apply(mort15cod[,2:8],2,unique))))


#h[3698]
##We can take the inclusion of all levels for these factors to make a categorical matrix on which we can analyse COD
mort15cod[,2]<-factor(mort15cod[,2],levels=h)
str(mort15cod)
mort15cod[,3]<-factor(mort15cod[,3],levels=h)
mort15cod[,4]<-factor(mort15cod[,4],levels=h)
mort15cod[,5]<-factor(mort15cod[,5],levels=h)
mort15cod[,6]<-factor(mort15cod[,6],levels=h)
mort15cod[,7]<-factor(mort15cod[,7],levels=h)
mort15cod[,8]<-factor(mort15cod[,8],levels=h)

str(mort15cod)
mort15 <- mort15[which(mort15$V44 %in% mort15cod$V44),]

write.csv(mort15, "Mortality15CODPurge.csv")
mort15cod <- read.csv("Mortality15CODPurge.csv")


```


#Cleaning Continued

Lastly we may want to exclude certain age groups from analysis. My own proclivities make me want to focus only on people aged 18 and up.
That is, those whose AgeDetail is between 1017 and 1200. This would allow us to delete Infant Cause Recode from our list.

Other Recodes are not as easily replaced as age recodes, and additionally we may want to take a closer look at them with clustering analyses.
```{r}
mort15$RaceRecord5 <- as.factor(mort15$RaceRecord5) #We'll also be needing this
```



```{r}
mort15 <- mort15[which(mort15$AgeDetail > 1017 & mort15$AgeDetail < 1999),]
mort15$AgeDetail <- (mort15$AgeDetail -1000) #The ages are stored with the first digit denoting Years/Months/Minutes of life. 1### is years, we don't need the others.
mort15$CauseRecode130 <- NULL #Recode 130 is specifically for infant mortalities

```

Finally we can look at deaths not directly related to health, such as accidental deaths.
Initially these may seem to be not all that relevant, but I have heard that accidental deaths correlate pretty strongly with suicides. 


This leaves us with things like homicide, car accidents, and warfare as our candidates for deletion. 
Non-health related deaths can be found by looking in the documentation. The upper registers of CauseRecode358 are all non-disease related deaths including homicide, accidental poisoning, and so on, from 381 up.

One of our questions will involve comparing accidental and intentional self-harm. these entries will go on to form their own dataset

The groups 384 and up can be thought of roughly as: 

456 D 453 Medical Malpractise
452 D 449 Law Enforement Soldiering
448 - 442 Unknown intent death guns/poison
441 D 432 Assault and Homicide 
431 - 424 Suicide Self Harm
423 - 419 Accidental Poisoning
418 D 416 Acts of Nature
415 ? 407 Accidental / Building Hazard / Choking hazard
406 ? 403 Falling
402 D 381 Vehicular Accidents
  390 ? 384 Driver
  399 Unspecified
  400 Boating
  
$MannerofDeath also includes lists of deaths deemed accidental or of unknown cause. We'll shove aside the inclusion of both.

1 ... Accident
2 ... Suicide
3 ... Homicide
4 ... Pending investigation
5 ... Could not determine
6 ... Self-Inflicted
7 ... Natural                - This is what we want to start with.
Blank ... Not specified


```{r}
mort15selfharm <- mort15[-which(mort15$CauseRecode358 < 384),]
#These are all the self-harm and accidental, ie non-medical deaths
#We won't include them in our primary analysis, but we will look at them later to compare some results.

#which (c(384:390,400,407:415,419:423,424:431,442:448) %in% mort15$CauseRecode358[1:10000])

mort15 <- mort15[which(mort15$CauseRecode358 < 384),]
#table(mort15selfharm$MannerOfDeath)
mort15selfharm <- rbind.data.frame(mort15selfharm, mort15[which(mort15$MannerOfDeath == c(1:6)),])
mort15selfharm <- mort15selfharm[unique(mort15selfharm$V44),]
mort15 <- mort15[which(mort15$MannerOfDeath == 7),]


```

With these row exclusions out of the way we can start looking at some more in depth analysis.


#Data Analysis §1

The first step in a good analysis is to get a better understanding of the data and the trends in it.
Let's start by making a few visualizations, and asking some basic questions.
Some questions we might ask are...

1) When do people die?
2) How old are people when they die?
3) What are the differences between men and women?
4) What are the most common means of death?
5) Various factors vs Age of Death Re:gression
6) What is the distribution of these variables? - Normal? Skew? Flat?

```{r}
hist(mort15$MonthOfDeath)

```

As expected the colder months are not kind to the infirm.

```{r}
hist(mort15$AgeDetail, breaks=20)
median(mort15$AgeDetail)
mean(mort15$AgeDetail)
```
Adults live to around 77 years old.
The results are fairly right-skewed. Let's see how these numbers differ among the sexes.


```{r}
hist(mort15$AgeDetail[which(mort15$Sex =='M')], breaks=20)
hist(mort15$AgeDetail[which(mort15$Sex =='F')], breaks=20)
median(mort15$AgeDetail[which(mort15$Sex =='M')])
median(mort15$AgeDetail[which(mort15$Sex =='F')])
```
As one often hears, women live longer than men with 82 and 75 being the respective median ages of death.



What are some of the leading and least common causes of death? We'll look at the CauseRecode113 as opposed to ICD10 for a more
general picture.

```{r}
sort(table(mort15$CauseRecode113))
```

Recodes 111, 63, 27, 86, and 70 are the most common methods of death
7, 8, 13, 2, and 17 the least common. 

From the literature we find out that these are...
Top: Misc. Disease, Chronic Ischemic Heart Disease, Lung/Trachea/Bronchus Neoplasms ie cancer, Chronic Lung Disease, and Cerebrovascular Disease
(including Arterio-venus malformations?).
Bottom: Whooping Cough, Scarlet Fever, Encephalitis, Amoeba Infection, and Malaria.


 
```{r}


```




```{r}

```


#Data Analysis §2 
Now that we've gotten a look see at some of the trends let's do some more in depth analysis and computation


  One critical factor for determining life expectancy is wealth, which is not listed in this dataset. 
Question: Can we infer wealth information from other variables? The motivation here could be dimensionality reduction - imagine if this were REALLY big data.  Which variables could we infer it from? Five candidates:

Race - Unfortunately still a solid predictor of social status.
Education - More education leads to higher paying jobs.
Method of Dispostition - Burials are expensive. In 2014 the mean burial price was >$7000, per the mortician's association of USA. http://fortune.com/2015/10/30/cremation-death-funeral/
Marital Status - Married persons are on average wealthier. 
Age: Richer people can afford to live longer


Principle Component Analysis (PCA) alone won't solve the job here, since it relies on eigenvalue analysis over numerical data.
Our data is more categorical, requiring a different approach with a different metric. 

  What are some methods of PCA for mixed data types? FactoMineR has Factor Analysis of Mixed Data (FADM) for Exploratory Data Analysis.
What are the assumptions of PCA? At least for ordinal or interval variables there is an assumption of normality. It would help to deal 
with age in some way. I tried to look into Polychoric transformation but couldn't make heads or tails of it. Binning ages into roughly normal chunks gave slightly superior results (but only slightly).
  
  
```{r}
install.packages("FactoMineR")
#mort15$RaceRecord5, mort15$Education2003,  mort15$MethodOfDisposition, mort15$MaritalStatus
mort15[,5] <- as.numeric(mort15[,5])
mort15[,2] <- as.factor(mort15[,2])
str(mort15[,c(2,7,11,24)])
hist(mort15[,5])
table(mort15[,2])

#install.packages("polycor")
#library(polycor)
#mort15eduage <- hetcor(mort15[,c(2,5)])$correlations
#mort15eduage
#nScree(mort15eduage)

mort15famd <- FAMD(mort15[,c(2,28,7,11,24)], ncp=10, graph=T)
mort15fa
#library(FactoMineR)
summary(mort15famd)
plot(mort15famd$eig[c(3,1)])
quantile(mort15[,5], c(1:9)/10)


mort15[,28] <-mort15[,5]
#The eigenvalues increased when I changed education to a factor. Makes sense. We could try binning ages as normal and see if that changes much?
normquantage <- quantile(mort15[,5], c(0.036,0.067,0.115,0.184,0.274,0.382,0.5,0.618,0.726,0.816,0.885,0.933,0.964)) #we can use the quantile function to get cutoff ages for a more normal distribution. I looked up percentiles for zscores at 0.3 increments.
match(normquantage, sort(mort15[,5]))
mort15quantage[,3] <- cut(mort15quantage[,1], breaks=c(0,normquantage, Inf), labels=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13))
plot(mort15quantage[,3]) #Much more normal.
mort15[,28] <-mort15quantage[,3]

#table(mort15$MethodOfDisposition)
#Burial, Cremation, Unknown, Other, Removal From State, Donation, Entombment
#The plot with age as a normal inverval variable had more variance accounted for in the first factors. 
#After factor 4 the eigenvalues approach 1, meaning only 4 variables are doing the heavy lifting. 
#The fact that so little variance (16%) is accounted for by these could indicate we just have very noisy data.
#Skew -> Correlation, Low Values -> Noisiness.


#What about a multiple correspondance analysis since they're all factors now?
mort15mca <- MCA(mort15[,c(2,7,11,24,28)], ncp=10)
mort15mca$eig
#This is even worse somehow...
plot(mort15mca$eig[,c(3,1)])



```

  
```{r}

```

  Now for another challenge. The CDC bins cause of death into various groups named CauseRecode###, and does this mainly according to where the disease is located in the body. So we get lists which go heart disease, brain disease, lung disease, and so on. 
Question: Can we use machine learning techniques to look for less-expected correlations among diseases? For instance I've heard it said that poor dental health often leads to heart disease.
  
For the most part here we will be working with the X27 variable loaded into its own matrix mort15cod and cleaned up. It's a huge matrix of 5000+
causes and contributing causes of death. We'll try to cluster over it to produce our own binnings, and look for anything surprising. Kmodes clustering is good here. Kmeans requires a distance metric which we don't really have. A Kmodes implementation is included in the klaR package.

```{r}
#mort15ca <- (mort15cod[1:1000,2:8])
#mort15HCPC <- HCPC(mort15cod[1:1000,2:8])
install.packages("cluster")
library(cluster)

mort15cod <- mort15cod[which(mort15$V44 %in% mort15cod$V44),]


alpha<-NULL
set.seed(0)
#alpha <- rockCluster(x = as.matrix(mort15cod[sample(length(mort15cod$V44),size=1000),2:8]), n=39, theta=0.3, fun = "dist")
#?rockCluster
#alpha
set.seed(0)
library(klaR)
library(cluster)
aa <- sample(length(mort15cod$V44),size=10000)
alpha <- kmodes(mort15cod[aa,2:8],33,iter.max=20,weighted=F)
#I've looked for info on weights, but the original paper has been lost down the memory hole
#and none of the stackoverflow posts have any info. so it goes

#It's Recode 39, but really only 33 of them are used to begin with since we did so much slicing and dicing.
#length(table(mort15$CauseRecode39))

sort(table(mort15cod$rac1[which(alpha$cluster==1)]), decreasing=T)

alpha$cluster


sort(table(mort15$CauseRecode39[aa]))
sort(table(alpha$cluster))

#We've got roughly the same size clusters, likely due to rac1 and the matrix being mostly sparse. It's a start.
#iter=10 gave us mostly samey stuff.


cc<-mort15[aa,]

ee<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==6)]),decreasing=T)[1:20])))
  sort(table(cc$CauseRecode39[which(as.numeric(alpha$cluster)==6)]),decreasing=T)[1:20] 
  #ie which cause recodes do our own clusters match most? 
  #Another way to look at it is alphabetically. Different Letter -> Different Style of Death.
ff<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==4)]),decreasing=T)[1:20])))
  #sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==4)]),decreasing=T)[1:20]
gg<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==3)]),decreasing=T)[1:20])))
  #sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==3)]),decreasing=T)[1:20]
hh<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==2)]),decreasing=T)[1:20])))
  #sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==2)]),decreasing=T)[1:20]
ii<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==1)]),decreasing=T)[1:20])))
  #sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==1)]),decreasing=T)[1:20]
jj<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==8)]),decreasing=T)[1:20])))
  sort(table(cc$ICDCode[which(as.numeric(alpha$cluster)==8)]),decreasing=T)[1:20]

  


table(cc[match(ee,cc$ICDCode),18]) 
idc <- read.csv("Icd10Code.csv")
idc$Code <- as.character(idc$Code)

#use a loop to get which ones are doing stuff? No! match() instead of %in%

idc$Description[match(ee, idc$Code)]
idc$Description[match(ff, idc$Code)]
idc$Description[match(gg, idc$Code)]
idc$Description[match(hh, idc$Code)]
idc$Description[match(ii, idc$Code)]
idc$Description[match(jj, idc$Code)]



mort15cod[1,]

coddaisy <- daisy(mort15cod[aa,2:8])
summary(coddaisy)
codmatrix <- as.matrix(coddaisy)

mort15codaa <- mort15cod[aa,]
mort15codaa[which(codmatrix == min(codmatrix[codmatrix != min(codmatrix)]),arr.ind = TRUE)[1, ], ] #The most similar pair

mort15codaa[which(codmatrix == max(codmatrix[codmatrix != max(codmatrix)]),arr.ind = TRUE)[1, ], ] #The most dissimilar pair


codpam2 <- pam(coddaisy2, diss=T, k=12)
sort(table(codpam2$clustering))

eee<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==7)]),decreasing=T)[1:20])))
fff<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==1)]),decreasing=T)[1:20])))
ggg<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==6)]),decreasing=T)[1:20])))
hhh<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==11)]),decreasing=T)[1:20])))
iii<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==10)]),decreasing=T)[1:20])))
jjj<- trimws(unlist(dimnames(sort(table(cc$ICDCode[which(as.numeric(codpam2$clustering)==12)]),decreasing=T)[1:20])))

eee
idc$Description[match(eee, idc$Code)]
idc$Description[match(fff, idc$Code)]
idc$Description[match(ggg, idc$Code)]
idc$Description[match(hhh, idc$Code)]
idc$Description[match(iii, idc$Code)]
idc$Description[match(jjj, idc$Code)]


#install.packages("klaR")
#library(klaR)
#library(tidyr)
#write.csv(mort15cod, "mort15codfz.csv")


```

A lot of this is shamelessly stolen from rbloggers. 
  
 
```{r}

b <- cbind(mort15cod[aa,2:8],cc[,4:5]) #Our  newfangled mixed matrix for Pam analysis.
coddaisy2 <- daisy(b)

codmatrix2 <- as.matrix(coddaisy2)


b[which(codmatrix2 == min(codmatrix2[codmatrix2 != min(codmatrix2)]),arr.ind = TRUE)[1, ], ] #The most similar pair
b[which(codmatrix2 == max(codmatrix2[codmatrix2 != max(codmatrix2)]),arr.ind = TRUE)[1, ], ] #The most dissimilar pair

sil_width <- c(NA)

for(i in 2:25){
  
  codsil2 <- pam(coddaisy2,
                 diss = TRUE,
                 k = i)
  
  sil_width[i] <- codsil2$silinfo$avg.width
  
}

# Plot sihouette width (higher is better)

plot(1:24, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:24, sil_width)

#It's quite noisy. On the whole none of these values are very good. 26 is the last good one even, the rest are just around 0.
#Tomorrow I'll try with age and gender.
```

```{r}

```

```{r}
```

ICD Codes from Kaggle
rbloggers for PAM
```{r}

```
